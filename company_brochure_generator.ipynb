{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86832e26-bf26-4024-8933-2833e6cf7569",
   "metadata": {},
   "source": [
    "# Company Website Brochure Generator Tool\n",
    "\n",
    "**Author**: [Pouria Ebrahimnezhad]  \n",
    "**Date**: [2025-02-12]  \n",
    "\n",
    "## Overview\n",
    "This notebook is designed to scrape content from a website and generate a brochure using both cloud-based and local LLM models. It leverages web scraping tools, OpenAI API, Google Gemini, Anthropic Claude, and Gradio for an interactive interface.\n",
    "\n",
    "## Key Technologies:\n",
    "- **Web Scraping**: `requests`, `BeautifulSoup`\n",
    "- **LLM Integration**: `OpenAI`, `google.generativeai`, `anthropic`\n",
    "- **Environment Management**: `dotenv`\n",
    "- **UI & Display**: `gradio`, `IPython.display.Markdown`\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87927392-0790-407d-9f21-ff1d56779d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af652a-9383-4837-8f42-37010aefff88",
   "metadata": {},
   "source": [
    "## Testing the OpenAI API key and the local LLM models\n",
    "\n",
    "Here we initiate a test to make sure we can access the OpenAI models using the API key we have and that we are able to retrieve response from a llm model in this case the gpt-4o-mini.\n",
    "Note you will need to setup the key in a .env file in your environment for this to work.\n",
    "\n",
    "We also test the local model in this case llama3.2 using Ollama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bf3c4de-42a3-4b8c-be64-8b3570845621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "062fdf21-6630-4676-a5f8-0702eef8f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI\n",
    "openai = OpenAI()\n",
    "system_message = \"You are a helpful assistant that responds in markdown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "df56e045-d00b-4b84-a734-524aa0e30378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def message_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    completion = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def display_markdown(response):\n",
    "    display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab2b9824-fc7a-4f0d-879a-521a5e9ad31f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Delicious Carrot Cake Recipe\n",
       "\n",
       "### Ingredients\n",
       "\n",
       "#### For the Cake:\n",
       "- **2 cups** all-purpose flour\n",
       "- **2 tsp** baking powder\n",
       "- **1 tsp** baking soda\n",
       "- **1/2 tsp** salt\n",
       "- **1 tsp** ground cinnamon\n",
       "- **1/2 tsp** ground nutmeg\n",
       "- **1/2 tsp** ground ginger\n",
       "- **1 cup** vegetable oil\n",
       "- **1 cup** granulated sugar\n",
       "- **1 cup** packed brown sugar\n",
       "- **4 large** eggs\n",
       "- **2 cups** grated carrots (about 4 medium carrots)\n",
       "- **1/2 cup** crushed pineapple, drained\n",
       "- **1/2 cup** chopped walnuts or pecans (optional)\n",
       "- **1/2 cup** raisins (optional)\n",
       "- **1 tsp** vanilla extract\n",
       "\n",
       "#### For the Cream Cheese Frosting:\n",
       "- **8 oz** cream cheese, softened\n",
       "- **1/2 cup** unsalted butter, softened\n",
       "- **4 cups** powdered sugar\n",
       "- **1 tsp** vanilla extract\n",
       "\n",
       "### Instructions\n",
       "\n",
       "#### For the Cake:\n",
       "1. **Preheat your oven** to 350°F (175°C). Grease and flour two 9-inch round cake pans.\n",
       "2. In a medium bowl, **whisk together** the flour, baking powder, baking soda, salt, cinnamon, nutmeg, and ginger. Set aside.\n",
       "3. In a large bowl, **mix together** the vegetable oil, granulated sugar, and brown sugar until well combined.\n",
       "4. **Add the eggs**, one at a time, beating well after each addition. Stir in the grated carrots, crushed pineapple, walnuts, raisins, and vanilla extract.\n",
       "5. Gradually **add the dry ingredients** to the wet mixture, stirring just until combined.\n",
       "6. **Divide the batter** evenly between the two prepared cake pans.\n",
       "7. **Bake** for 25-30 minutes, or until a toothpick inserted into the center comes out clean.\n",
       "8. Allow the cakes to **cool in the pans** for 10 minutes, then transfer to wire racks to cool completely.\n",
       "\n",
       "#### For the Cream Cheese Frosting:\n",
       "1. In a medium bowl, **beat the softened cream cheese and butter** together until smooth and creamy.\n",
       "2. Gradually add the powdered sugar, continuing to beat until fully combined and fluffy.\n",
       "3. Stir in the vanilla extract.\n",
       "\n",
       "### Assembly:\n",
       "1. Once the cakes are completely cool, place one layer on a serving plate.\n",
       "2. **Spread a layer of frosting** over the top of the first layer.\n",
       "3. Place the second layer on top and frost the top and sides of the cake.\n",
       "4. **Decorate** with additional walnuts or grated carrots, if desired.\n",
       "\n",
       "### Enjoy!\n",
       "Serve at room temperature, and enjoy a slice of this moist and flavorful carrot cake with family and friends!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_markdown(message_gpt(\"what is a good recepie for carrot cake\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "57bacd51-2907-4a24-b76e-55a903a19a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The question of the meaning of life is one of the most profound and enduring questions in human history. It has been debated, explored, and contemplated by philosophers, theologians, scientists, and countless individuals throughout time. There is no one definitive answer to this question, as it can be subjective, context-dependent, and multifaceted.\n",
      "\n",
      "That being said, here are some perspectives that might offer insights into the meaning of life:\n",
      "\n",
      "1. **Religious or spiritual perspectives**: Many religions and spiritual traditions provide their own answers to this question. For example, in Christianity, the purpose of life is often seen as serving God and fulfilling one's role in the plan of salvation. In Buddhism, it is believed that the goal of life is to attain enlightenment and escape the cycle of rebirth.\n",
      "2. **Humanistic perspectives**: Some philosophers argue that the meaning of life can be found in human experience itself. According to this view, life has value because of our relationships, emotions, thoughts, and experiences. This perspective emphasizes the importance of personal growth, self-actualization, and contributing to the greater good.\n",
      "3. **Scientific perspectives**: From a scientific standpoint, life is often seen as an emergent property of complex systems and processes. According to this view, the meaning of life might be found in the pursuit of understanding and exploring the natural world, rather than in any inherent purpose or value.\n",
      "4. **Existentialist perspectives**: Existentialism posits that life has no inherent meaning; instead, it is up to each individual to create their own purpose and meaning through their choices and actions.\n",
      "5. **Personal perspectives**: Ultimately, the meaning of life can be a deeply personal question that each individual must answer for themselves. Some people find meaning in their relationships, work, or creative pursuits. Others may seek answers from philosophy, spirituality, or scientific inquiry.\n",
      "\n",
      "Some popular theories about the meaning of life include:\n",
      "\n",
      "* **The Self-Actualization Theory**: Proposed by psychologist Abraham Maslow, this theory suggests that people have a fundamental drive to self-actualize and fulfill their potential.\n",
      "* **The Purpose Theory**: This theory proposes that life has a inherent purpose or direction that can be discovered through reflection, experience, and exploration.\n",
      "* **The Hedonic Theory**: According to this perspective, the meaning of life is found in the pursuit of happiness and pleasure.\n",
      "\n",
      "In conclusion, the meaning of life is a complex and multifaceted question that cannot be reduced to a single answer. Different perspectives offer insights, but ultimately, it is up to each individual to explore and create their own purpose and meaning in life.\n"
     ]
    }
   ],
   "source": [
    "# testing if local ollama is running and able to get a response from the model\n",
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is the meaning of life?\"}\n",
    "]\n",
    "\n",
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50def1de-6775-4bb4-bf27-88b903ce526a",
   "metadata": {},
   "source": [
    "## Building the Website scraper and broucher builder\n",
    "\n",
    "Here we define the required functions and class for scraping a website based on its url and returning a text which includes the title of the webpage along with its content\n",
    "we then define a system message for the large language model along with two streaming functions used for each llm one for the OpenAI model and one for the local llama model.\n",
    "\n",
    "We then finally build a stream broucher for streaming the results of the models and then use Gradio interface to be the front-end GUI for this tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b529367-0fa7-4698-a15e-10b5304812f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "\n",
    "class Website:\n",
    "    url: str\n",
    "    title: str\n",
    "    text: str\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        response = requests.get(url)\n",
    "        self.body = response.content\n",
    "        soup = BeautifulSoup(self.body, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "    def get_contents(self):\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2beb872-1720-453b-a8c0-89a530fc26b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a system_message that will be provided to the llm\n",
    "system_message = \"You are an assistant that analyzes the contents of a company website landing page \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e8f09f0-4798-4e01-a9ac-512eb95cf56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_llama(prompt):\n",
    "    stream = ollama_via_openai.chat.completions.create(\n",
    "        model=\"llama3.2\",  # Replace with your local Llama model name if different\n",
    "        messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        stream=True  # Enable streaming\n",
    "    )\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        if chunk.choices and chunk.choices[0].delta.content:\n",
    "            text = chunk.choices[0].delta.content\n",
    "            response += text\n",
    "            yield response\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a7add7f-32ca-47b6-b0e4-8912521127ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model):\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += Website(url).get_contents()\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"llama3.2\":\n",
    "        result = stream_llama(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f729be3f-eb2b-4c1f-bb47-453fe5643d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company name:\"),\n",
    "        gr.Textbox(label=\"Landing page URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"GPT\", \"llama3.2\"], label=\"Select model\")],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    flagging_mode=\"never\",\n",
    "    js=force_dark_mode\n",
    ")\n",
    "view.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
